{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import sqlite3\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import Article\n",
    "from newscatcher import Newscatcher, describe_url, urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class news_crawl:\n",
    "    def __init__(self):\n",
    "        self.now = datetime.today()\n",
    "        self.now_1d = datetime.today() - timedelta(days=1)\n",
    "        self.today = datetime.today().strftime(\"%Y-%m-%d %H:%M\")\n",
    "        self.yesterday = (self.now - timedelta(days=1)).strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "        # self.yesterday = datetime.today() - timedelta(days=1)\n",
    "        \n",
    "        self.news_dir = os.path.join(os.getcwd(),'data','news')\n",
    "        \n",
    "        self.news_topic = ['tech', 'news', 'business', 'science', 'finance', 'food', 'politics', 'economics', 'travel', 'entertainment', 'music', 'sport', 'world']\n",
    "        self.news_url = {\n",
    "                        'newyork_times': 'nytimes.com',\n",
    "                        'washington_post':'washingtonpost.com',\n",
    "                        # 'wallstreet_journal':'wsj.com',\n",
    "                        # 'bloomberg':'bloomberg.com',\n",
    "                        'cnn':'cnn.com',\n",
    "                        'cnbc':'cnbc.com',\n",
    "                        'financial_times':'ft.com/',\n",
    "                        # 'reuters':'reuters.com'\n",
    "                    }\n",
    "        self.news_url_list = list(self.news_url.values())\n",
    "\n",
    "\n",
    "    def crawl_news_data(self):\n",
    "\n",
    "    # [source, topic, title, publish_date, link, text]\n",
    "    # link = news_url, newspaper3k package will load news contents\n",
    "    # link from newscatcher, text from newspaper3k\n",
    "        news_base_data = []\n",
    "        number = 0\n",
    "\n",
    "        for base_url in self.news_url_list:\n",
    "            \n",
    "            number += 1\n",
    "            print(number, base_url)\n",
    "            \n",
    "            # topics of base_url\n",
    "            topics = describe_url(base_url)['topics']\n",
    "            \n",
    "            # loop each topics\n",
    "            try:\n",
    "                for topic in topics:\n",
    "                    nc = Newscatcher(base_url, topic = topic)\n",
    "                    results = nc.get_news()\n",
    "                    articles = results['articles']\n",
    "\n",
    "                    # base_url - topic pair\n",
    "                    for article in articles:\n",
    "                        title = article['title']\n",
    "                        pub_date = article['published']\n",
    "                        link = article['link']\n",
    "\n",
    "                        temp = []\n",
    "\n",
    "                        temp.append(base_url)\n",
    "                        temp.append(topic)\n",
    "                        temp.append(title)\n",
    "                        temp.append(pub_date)\n",
    "                        temp.append(link)\n",
    "\n",
    "                        news_base_data.append(temp)\n",
    "\n",
    "            except:\n",
    "                print(\"not_available\", base_url, topic, title)\n",
    "\n",
    "        df_news_base_data = pd.DataFrame(news_base_data, columns=['source','topic','title','publish_date','link'])\n",
    "\n",
    "        df_news_base_data['date'] = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "        df_news_base_data['keyword'] = ''\n",
    "        df_news_base_data['text'] = ''\n",
    "\n",
    "        try:\n",
    "            for i in df_news_base_data.index:\n",
    "                # datetime conversion for publish date to 2022-03-22 09:00 format\n",
    "                _str_datetime = df_news_base_data.loc[i,'publish_date'][:22]\n",
    "                _stf_datetime = datetime.strptime(_str_datetime, '%a, %d %b %Y %H:%M')\n",
    "                datetime_str = datetime.strftime(_stf_datetime, '%Y-%m-%d %H:%M')\n",
    "                df_news_base_data.loc[i,'publish_date'] = datetime_str\n",
    "\n",
    "            df_news_base_data = df_news_base_data.query(f\"publish_date > '{self.yesterday}' and publish_date < '{self.now}'\")\n",
    "            df_news_base_data = df_news_base_data.reset_index(drop=True)\n",
    "        except:\n",
    "            print(\"publish date columns something wrong\")\n",
    "\n",
    "        try:\n",
    "            for i in df_news_base_data.index:\n",
    "                print(i, df_news_base_data.loc[i,'source'], df_news_base_data.loc[i,'title'])\n",
    "\n",
    "                url = df_news_base_data.loc[i, 'link']\n",
    "                article = Article(df_news_base_data.loc[i,'link'], language='en')\n",
    "\n",
    "                article.download()\n",
    "                article.parse()\n",
    "                article.nlp()\n",
    "\n",
    "                title, keywords, text = article.title, article.keywords, article.text\n",
    "\n",
    "                keyword_str = ''\n",
    "                for keyword in keywords:\n",
    "                    keyword_str = keyword_str + keyword + '/'\n",
    "\n",
    "                df_news_base_data.loc[i ,'keyword'] = keyword_str\n",
    "                df_news_base_data.loc[i ,'text'] = text\n",
    "                    \n",
    "        except:\n",
    "            print(i, df_news_base_data.loc[i,'source'], df_news_base_data.loc[i,'title'])\n",
    "        \n",
    "        # filter last 24 hour news\n",
    "        df_news_base_data = df_news_base_data.reset_index(drop=True)\n",
    "\n",
    "        df_news_base_data = df_news_base_data[['date','publish_date','source','topic','title','keyword','link','text']]\n",
    "        df_news_base_data.to_excel(os.path.join(self.news_dir,f'{self.now.strftime(\"%Y-%m-%d\")}_news.xlsx'))\n",
    "        return df_news_base_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 nytimes.com\n",
      "2 washingtonpost.com\n",
      "\n",
      "No results found check internet connection or query parameters\n",
      "\n",
      "washingtonpost.com news Behind the Nickel Mess on the London Metal Exchange\n",
      "3 cnn.com\n",
      "cnn.com world Women still earn less than men. 6 leaders explain how to fix that\n",
      "4 cnbc.com\n",
      "5 ft.com/\n",
      "\n",
      "No results found check internet connection or query parameters\n",
      "\n",
      "ft.com/ news Amazon closes $8.45bn deal to acquire film studio MGM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>topic</th>\n",
       "      <th>title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>link</th>\n",
       "      <th>date</th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [source, topic, title, publish_date, link, date, keyword, text]\n",
       "Index: []"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_today = news_crawl()\n",
    "df_news = news_today.crawl_news_data()\n",
    "df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create table news_data \n",
    "(\n",
    "\tid BIGSERIAL PRIMARY KEY,\n",
    "\tdate VARCHAR(32),\n",
    "\tpublish_date TIMESTAMP ,\n",
    "\tsource VARCHAR(32),\n",
    "\ttopic VARCHAR(32),\t\n",
    "\ttitle TEXT,\n",
    "\tkeyword TEXT,\n",
    "\tlink TEXT,\n",
    "\ttext TEXT\n",
    ");\n",
    "\n",
    "select * from news_data;\n",
    "\n",
    "--truncate news_data;\n",
    "--drop news_data;\n",
    "commit;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
