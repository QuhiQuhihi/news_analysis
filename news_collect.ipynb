{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import sqlite3\n",
    "import calendar\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import Article\n",
    "from newscatcher import Newscatcher, describe_url, urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class news_crawl:\n",
    "    def __init__(self):\n",
    "        self.now = datetime.today()\n",
    "        self.now_1d = datetime.today() - timedelta(days=1)\n",
    "        self.today = datetime.today().strftime(\"%Y-%m-%d %H:%M\")\n",
    "        self.yesterday = (self.now - timedelta(days=1)).strftime(\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "        # self.yesterday = datetime.today() - timedelta(days=1)\n",
    "        \n",
    "        self.news_dir = os.path.join(os.getcwd(),'data','news')\n",
    "        \n",
    "        self.news_topic = ['tech', 'news', 'business', 'science', 'finance', 'politics', 'economics',  'world']\n",
    "        self.news_url = {\n",
    "                        'newyork_times': 'nytimes.com',\n",
    "                        'washington_post':'washingtonpost.com',\n",
    "                        'cnn':'edition.cnn.com',\n",
    "                        'fox': 'foxnews.com',\n",
    "                        'bbc' : 'bbc.co.uk',\n",
    "                        'cnbc':'cnbc.com',\n",
    "                        'financial_times':'ft.com',\n",
    "                        'yahoo':'yahoo.com',\n",
    "                        'guardian':'theguardian.com',\n",
    "                        'telegraph':'telegraph.co.uk',\n",
    "                    }\n",
    "        self.news_url_list = list(self.news_url.values())\n",
    "\n",
    "\n",
    "    def crawl_news_data(self):\n",
    "\n",
    "    # [source, topic, title, publish_date, link, text]\n",
    "    # link = news_url, newspaper3k package will load news contents\n",
    "    # link from newscatcher, text from newspaper3k\n",
    "        news_base_data = []\n",
    "        number = 0\n",
    "\n",
    "        for base_url in self.news_url_list:\n",
    "            \n",
    "            number += 1\n",
    "            print(number, base_url)\n",
    "            \n",
    "            # topics of base_url\n",
    "            topics = describe_url(base_url)['topics']\n",
    "            \n",
    "            # loop each topics\n",
    "            try:\n",
    "                for topic in topics:\n",
    "                    nc = Newscatcher(base_url, topic = topic)\n",
    "                    results = nc.get_news()\n",
    "                    articles = results['articles']\n",
    "\n",
    "                    # base_url - topic pair\n",
    "                    for article in articles:\n",
    "                        title = article['title']\n",
    "                        pub_date = article['published']\n",
    "                        link = article['link']\n",
    "\n",
    "                        temp = []\n",
    "\n",
    "                        temp.append(base_url)\n",
    "                        temp.append(topic)\n",
    "                        temp.append(title)\n",
    "                        temp.append(pub_date)\n",
    "                        temp.append(link)\n",
    "\n",
    "                        news_base_data.append(temp)\n",
    "                        time.sleep(1)\n",
    "\n",
    "            except:\n",
    "                print(\"not_available\", base_url)\n",
    "\n",
    "        df_news_base_data = pd.DataFrame(news_base_data, columns=['source','topic','title','publish_date','link'])\n",
    "\n",
    "        df_news_base_data['date'] = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "        df_news_base_data['keyword'] = ''\n",
    "        df_news_base_data['text'] = ''\n",
    "\n",
    "        try:\n",
    "            for i in df_news_base_data.index:\n",
    "                # datetime conversion for publish date to 2022-03-22 09:00 format\n",
    "                _str_datetime = df_news_base_data.loc[i,'publish_date'][:22]\n",
    "                _stf_datetime = datetime.strptime(_str_datetime, '%a, %d %b %Y %H:%M')\n",
    "                datetime_str = datetime.strftime(_stf_datetime, '%Y-%m-%d %H:%M')\n",
    "                df_news_base_data.loc[i,'publish_date'] = datetime_str\n",
    "\n",
    "            df_news_base_data = df_news_base_data.query(f\"publish_date > '{self.yesterday}' and publish_date < '{self.now}'\")\n",
    "            df_news_base_data = df_news_base_data.reset_index(drop=True)\n",
    "        except:\n",
    "            print(\"publish date columns something wrong\")\n",
    "\n",
    "        try:\n",
    "            for i in df_news_base_data.index:\n",
    "                print(i, df_news_base_data.loc[i,'source'], df_news_base_data.loc[i,'title'])\n",
    "\n",
    "                url = df_news_base_data.loc[i, 'link']\n",
    "                article = Article(df_news_base_data.loc[i,'link'], language='en')\n",
    "\n",
    "                article.download()\n",
    "                article.parse()\n",
    "                article.nlp()\n",
    "\n",
    "                title, keywords, text = article.title, article.keywords, article.text\n",
    "\n",
    "                keyword_str = ''\n",
    "                for keyword in keywords:\n",
    "                    keyword_str = keyword_str + keyword + '/'\n",
    "\n",
    "                df_news_base_data.loc[i ,'keyword'] = keyword_str\n",
    "                df_news_base_data.loc[i ,'text'] = text\n",
    "                time.sleep(1)\n",
    "                    \n",
    "        except:\n",
    "            print(i, df_news_base_data.loc[i,'source'], df_news_base_data.loc[i,'title'])\n",
    "        \n",
    "        # filter last 24 hour news\n",
    "        df_news_base_data = df_news_base_data.reset_index(drop=True)\n",
    "\n",
    "        df_news_base_data = df_news_base_data[['date','publish_date','source','topic','title','keyword','link','text']]\n",
    "        df_news_base_data.to_excel(os.path.join(self.news_dir,f'{self.now.strftime(\"%Y-%m-%d\")}_news.xlsx'))\n",
    "\n",
    "        return df_news_base_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 wsj.com/news/markets\n",
      "\n",
      "No results found check internet connection or query parameters\n",
      "\n",
      "not_available wsj.com/news/markets\n",
      "2 bloomberg.com/markets\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/workspace/news_analysis/news_collect.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/workspace/news_analysis/news_collect.ipynb#ch0000003vscode-remote?line=0'>1</a>\u001b[0m news_today \u001b[39m=\u001b[39m news_crawl()\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/workspace/news_analysis/news_collect.ipynb#ch0000003vscode-remote?line=1'>2</a>\u001b[0m df_news \u001b[39m=\u001b[39m news_today\u001b[39m.\u001b[39;49mcrawl_news_data()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/workspace/news_analysis/news_collect.ipynb#ch0000003vscode-remote?line=2'>3</a>\u001b[0m df_news\n",
      "\u001b[1;32m/mnt/c/workspace/news_analysis/news_collect.ipynb Cell 3'\u001b[0m in \u001b[0;36mnews_crawl.crawl_news_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/workspace/news_analysis/news_collect.ipynb#ch0000002vscode-remote?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m(number, base_url)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/workspace/news_analysis/news_collect.ipynb#ch0000002vscode-remote?line=40'>41</a>\u001b[0m \u001b[39m# topics of base_url\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/workspace/news_analysis/news_collect.ipynb#ch0000002vscode-remote?line=41'>42</a>\u001b[0m topics \u001b[39m=\u001b[39m describe_url(base_url)[\u001b[39m'\u001b[39m\u001b[39mtopics\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/workspace/news_analysis/news_collect.ipynb#ch0000002vscode-remote?line=43'>44</a>\u001b[0m \u001b[39m# loop each topics\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/workspace/news_analysis/news_collect.ipynb#ch0000002vscode-remote?line=44'>45</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/c/workspace/news_analysis/.env_news/lib/python3.8/site-packages/newscatcher/__init__.py:202\u001b[0m, in \u001b[0;36mdescribe_url\u001b[0;34m(website)\u001b[0m\n\u001b[1;32m    <a href='file:///mnt/c/workspace/news_analysis/.env_news/lib/python3.8/site-packages/newscatcher/__init__.py?line=198'>199</a>\u001b[0m sql \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSELECT clean_url, language, clean_country, topic_unified from rss_main WHERE clean_url = \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m and main == 1 \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    <a href='file:///mnt/c/workspace/news_analysis/.env_news/lib/python3.8/site-packages/newscatcher/__init__.py?line=199'>200</a>\u001b[0m     website)\n\u001b[1;32m    <a href='file:///mnt/c/workspace/news_analysis/.env_news/lib/python3.8/site-packages/newscatcher/__init__.py?line=200'>201</a>\u001b[0m results \u001b[39m=\u001b[39m db\u001b[39m.\u001b[39mexecute(sql)\u001b[39m.\u001b[39mfetchone()\n\u001b[0;32m--> <a href='file:///mnt/c/workspace/news_analysis/.env_news/lib/python3.8/site-packages/newscatcher/__init__.py?line=201'>202</a>\u001b[0m main \u001b[39m=\u001b[39m results[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\n\u001b[1;32m    <a href='file:///mnt/c/workspace/news_analysis/.env_news/lib/python3.8/site-packages/newscatcher/__init__.py?line=203'>204</a>\u001b[0m \u001b[39mif\u001b[39;00m main \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///mnt/c/workspace/news_analysis/.env_news/lib/python3.8/site-packages/newscatcher/__init__.py?line=204'>205</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mWebsite not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "news_today = news_crawl()\n",
    "df_news = news_today.crawl_news_data()\n",
    "df_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create table news_data \n",
    "(\n",
    "\tid BIGSERIAL PRIMARY KEY,\n",
    "\tdate VARCHAR(32),\n",
    "\tpublish_date TIMESTAMP ,\n",
    "\tsource VARCHAR(32),\n",
    "\ttopic VARCHAR(32),\t\n",
    "\ttitle TEXT,\n",
    "\tkeyword TEXT,\n",
    "\tlink TEXT,\n",
    "\ttext TEXT\n",
    ");\n",
    "\n",
    "select * from news_data;\n",
    "\n",
    "--truncate news_data;\n",
    "--drop news_data;\n",
    "commit;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
